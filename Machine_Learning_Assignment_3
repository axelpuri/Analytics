HONOUR CODE:

I solemnly swear that I have not discussed my assignment solutions with anyone in any way and the solutions I am submitting are my own personal work.

Full Name: Akhil Puri

ASSIGNMENT 3¶
QUESTION 1
Our main task is to use the Naive_Bayes classifier both BernoulliNB and GaussianNB and a hybrid model of the two for predicting whether the annual income of a certain individual is high or low based on descriptie features like age , education , workclass, marital_status, occupation and annual_income and to report on their performance using the accuracy metric .

PART A
TASK 1 - Discretizing Numeric Features
# Importing modules
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
import statsmodels.formula.api as smf
import patsy
import warnings
import sklearn 
###
warnings.filterwarnings('ignore')
###
%matplotlib inline 
%config InlineBackend.figure_format = 'retina'
plt.style.use("ggplot")
pd.options.display.float_format = '{:20,.3f}'.format
#Importing the data

df = pd.read_csv("C:/Users/axelp/Documents/RMIT/Semester 4/Machine Learning/Assignment 3/data.csv")

df.head()
row_id	age	education_years	workclass	marital_status	occupation	annual_income
0	1	48	14	Local-gov	Divorced	Prof-specialty	high_income
1	2	23	13	Local-gov	Never-married	Prof-specialty	low_income
2	3	45	13	Local-gov	Never-married	Prof-specialty	low_income
3	4	51	13	Federal-gov	Married-civ-spouse	Exec-managerial	low_income
4	5	51	14	Local-gov	Married-civ-spouse	Prof-specialty	high_income
# Lets first confirm that the descriptive features and types match the data outlined in the Assignment 3 comma separated file.

print(f"Shape of the dataset is {df.shape} \n")
print(f"Data types are below where 'object' indicates a string type: ")
print(df.dtypes)
Shape of the dataset is (500, 7) 

Data types are below where 'object' indicates a string type: 
row_id              int64
age                 int64
education_years     int64
workclass          object
marital_status     object
occupation         object
annual_income      object
dtype: object
#Checking for missing values 

print(f"\nNumber of missing values for each feature:")
print(df.isnull().sum())
Number of missing values for each feature:
row_id             0
age                0
education_years    0
workclass          0
marital_status     0
occupation         0
annual_income      0
dtype: int64
#Our first task before we carry out any data preprocessing step for modelling purposes we split the dataset into 
#data and target. This is done with the purpose of the carrying out integer coding and OHE on the descriptive features 
#and target encoding on the variable that needs to be predicted 

data = df.drop(columns = 'annual_income').values

target = df['annual_income'].values
#Converting numpy array to a dataframe

df = pd.DataFrame(data)

df.columns = ['row_id','age','education_years', 'workclass', 'marital_status', 'occupation']

df.head()
row_id	age	education_years	workclass	marital_status	occupation
0	1	48	14	Local-gov	Divorced	Prof-specialty
1	2	23	13	Local-gov	Never-married	Prof-specialty
2	3	45	13	Local-gov	Never-married	Prof-specialty
3	4	51	13	Federal-gov	Married-civ-spouse	Exec-managerial
4	5	51	14	Local-gov	Married-civ-spouse	Prof-specialty
#drop the row_id column

df1 = df.drop(columns=['row_id'])

df1
age	education_years	workclass	marital_status	occupation
0	48	14	Local-gov	Divorced	Prof-specialty
1	23	13	Local-gov	Never-married	Prof-specialty
2	45	13	Local-gov	Never-married	Prof-specialty
3	51	13	Federal-gov	Married-civ-spouse	Exec-managerial
4	51	14	Local-gov	Married-civ-spouse	Prof-specialty
...	...	...	...	...	...
495	43	13	Local-gov	Never-married	Prof-specialty
496	48	16	Local-gov	Married-civ-spouse	Prof-specialty
497	53	10	Federal-gov	Married-civ-spouse	Exec-managerial
498	54	10	Local-gov	Never-married	Prof-specialty
499	31	10	Local-gov	Divorced	Adm-clerical
500 rows × 5 columns

#Transforming the 2 numerical features (age and education_years) into 2 (nominal) categorical features using equal-width binning
#Lets convert age first

df_2 = df1.copy()

df_2['age'] = pd.qcut(df_2['age'], q=3,labels=['low', 'mid', 'high'])

df_2['age'].value_counts()

df_2.head()
age	education_years	workclass	marital_status	occupation
0	high	14	Local-gov	Divorced	Prof-specialty
1	low	13	Local-gov	Never-married	Prof-specialty
2	mid	13	Local-gov	Never-married	Prof-specialty
3	high	13	Federal-gov	Married-civ-spouse	Exec-managerial
4	high	14	Local-gov	Married-civ-spouse	Prof-specialty
#Now converting education_years which is a numerical feature in the original dataset into a categorical variable 

df_all_cat = df_2.copy()

df_all_cat['education_years'] = pd.qcut(df_all_cat['education_years'], q=3,labels=['low', 'mid', 'high'])

df_all_cat['education_years'].value_counts()

df_all_cat.head()
age	education_years	workclass	marital_status	occupation
0	high	high	Local-gov	Divorced	Prof-specialty
1	low	mid	Local-gov	Never-married	Prof-specialty
2	mid	mid	Local-gov	Never-married	Prof-specialty
3	high	mid	Federal-gov	Married-civ-spouse	Exec-managerial
4	high	high	Local-gov	Married-civ-spouse	Prof-specialty
for col in df_all_cat.columns.tolist():  
    print(col + ':')
    print(df_all_cat[col].value_counts())
    print('********')
age:
mid     179
low     169
high    152
Name: age, dtype: int64
********
education_years:
mid     187
low     174
high    139
Name: education_years, dtype: int64
********
workclass:
Local-gov      225
State-gov      148
Federal-gov    127
Name: workclass, dtype: int64
********
marital_status:
Married-civ-spouse    230
Never-married         155
Divorced              115
Name: marital_status, dtype: int64
********
occupation:
Prof-specialty     224
Adm-clerical       159
Exec-managerial    117
Name: occupation, dtype: int64
********
TASK 2 - ONE HOT ENCODING
#Now that we have carried out discretization and equal width binning for the age and education_years variables, 
#lets carry out one hot encoding (OHE)for the categorical ordinal and nominal variables as set out in the instructions
#I have not carried out integer coding for the ordinal variables as it is specifically mentioned in the assignment description to carry out OHE for
#for all the categorical variables 

#Since we need to carry out OHE on the descriptive categorical variables this excludes the target 
#feature which we have already assigned to an array called target 

# get the list of categorical descriptive features
categorical_cols = df_all_cat.columns[df_all_cat.dtypes==object].tolist()

# if a categorical descriptive feature has only 2 levels,
# define only one binary variable
for col in categorical_cols:
    n = len(df_all_cat[col].unique())
    if (n == 2):
        df_all_cat[col] = pd.get_dummies(df_all_cat[col], drop_first=True)

# for other categorical features (with > 2 levels), 
# use regular one-hot-encoding 
# if a feature is numeric, it will be untouched
df_all_cat = pd.get_dummies(df_all_cat)

df_all_cat.head()
age_low	age_mid	age_high	education_years_low	education_years_mid	education_years_high	workclass_Federal-gov	workclass_Local-gov	workclass_State-gov	marital_status_Divorced	marital_status_Married-civ-spouse	marital_status_Never-married	occupation_Adm-clerical	occupation_Exec-managerial	occupation_Prof-specialty
0	0	0	1	0	0	1	0	1	0	1	0	0	0	0	1
1	1	0	0	0	1	0	0	1	0	0	0	1	0	0	1
2	0	1	0	0	1	0	0	1	0	0	0	1	0	0	1
3	0	0	1	0	1	0	1	0	0	0	1	0	0	1	0
4	0	0	1	0	0	1	0	1	0	0	1	0	0	0	1
df_all_cat_ohe = df_all_cat.copy()
print(df_all_cat_ohe.shape)
df_all_cat_ohe.head()
(500, 15)
age_low	age_mid	age_high	education_years_low	education_years_mid	education_years_high	workclass_Federal-gov	workclass_Local-gov	workclass_State-gov	marital_status_Divorced	marital_status_Married-civ-spouse	marital_status_Never-married	occupation_Adm-clerical	occupation_Exec-managerial	occupation_Prof-specialty
0	0	0	1	0	0	1	0	1	0	1	0	0	0	0	1
1	1	0	0	0	1	0	0	1	0	0	0	1	0	0	1
2	0	1	0	0	1	0	0	1	0	0	0	1	0	0	1
3	0	0	1	0	1	0	1	0	0	0	1	0	0	1	0
4	0	0	1	0	0	1	0	1	0	0	1	0	0	0	1
#Coyping df_all_cat_ohe into a dataframe called "Data" which is the standard nomenclature while training (fitting) and evaluating models

Data = df_all_cat_ohe.copy()
TARGET FEATURE ENCODING
Having split our dataset into descriptive features under data and target we now need to label encode our target feature and ensure that our the positive level (in this assignment the positive class is high_income)

First lets inspect and ascertain the number of instances for each label under the target feature

np.unique(target, return_counts=True)
(array(['high_income', 'low_income'], dtype=object),
 array([180, 320], dtype=int64))
As expected, "high_income" and "low_income" have 180 and 320 observations respectively. Next, let's encode these as 0 and 1 using LabelEncoder from the sklearn preprocessing module.

from sklearn import preprocessing

le = preprocessing.LabelEncoder()
le_fit = le.fit(target)
target_encoded_le = le_fit.transform(target)
Note that the LabelEncoder labels in an alphabetical order. That is, "high-income" is labeled as 0 and "low_income" is labeled as 1.

Let's check how the encoding was done. Here we need to be careful with respect to NumPy vs. Pandas variables. The return value of label encoding is a NumPy array, so you now need to use the np.unique method; because value_counts method belongs to the Pandas module and it will not work with a NumPy object.

#import numpy as np

print("Target Type:", type(target))

print("Counts Using NumPy:")
print(np.unique(target_encoded_le, return_counts = True))

#Coverting the array to a numpy dataframe and then using the 
print("Counts Using Pandas:")
print(pd.Series(target_encoded_le).value_counts())
Target Type: <class 'numpy.ndarray'>
Counts Using NumPy:
(array([0, 1]), array([180, 320], dtype=int64))
Counts Using Pandas:
1    320
0    180
dtype: int64
The above display vindicates my earlier assertion about the label encoding working alphabetically i.e. "high_income" has been label-encoded as 0 and "low_income" as 1 . This needs to be turned around . Since label encoding does not give us the result we want, we will have to manually define the labels ourselves. For this purpose, we can use the where() function in NumPy to perform a vectorized "if-else" operation as below. The syntax for this function is follows:

np.where(condition, value when condition is true, value when condition is false)

target_encoded_where = np.where(target=='high_income', 1, 0)

np.unique(target_encoded_where, return_counts = True)
(array([0, 1]), array([320, 180], dtype=int64))
Now we can see that array has been correctly encoded i.e. the 180 "high_income" elements of the array have the correct binary level of 1. We can now proceed with training and testing the different models (model fitting and evaluation)

#We need to send target_encoded_le back to target 

target= target_encoded_le

target[:5]
array([0, 1, 1, 1, 0])
PART B
BERNOULLI
For this part, train a Bernoulli NB model (with default parameters) using the train data and compute its accuracy on again train data.

#Importing the necessary packages 

from sklearn.naive_bayes import BernoulliNB
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split

from sklearn import metrics
from sklearn.metrics import accuracy_score
As mentioned in the assignment instructions we will be training and testing on the same data so we do not need to parition the dataset Naive Bayes classifier for multivariate Bernoulli models.
Like MultinomialNB, this classifier is suitable for discrete data. The difference is that while MultinomialNB works with occurrence counts, BernoulliNB is designed for binary/boolean features

#Fitting a BErnoulli Nb on trining data and testing on the training data 

# Bernoulli NB model with default parameters
X = Data
y = target

bnb = BernoulliNB()
bnb.fit(X, y)
labels_b = bnb.predict(Data)
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score 

bn_CM = confusion_matrix(y,labels_b)
print('Confusion matrix:', bn_CM)
print ('Accuracy using BernoulliNb:', accuracy_score(y,labels_b))
Confusion matrix: [[150  30]
 [ 54 266]]
Accuracy using BernoulliNb: 0.832
PART C
GAUSSIAN
Gaussian NB assumes that each descriptive feature follows a Gaussian probability distribution. However, this assumption no longer holds for this problem because all features will be binary after the data preparation tasks in Part A. Thus, the purpose of this part is to see what happens if you apply Gaussian NB on binary-encoded descriptive features.

# GaussianNB model with default parameters
X = Data
Y = target

gau = GaussianNB()
gau.fit(X, y)
labels_b = gau.predict(Data)
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score 

gau_CM = confusion_matrix(y,labels_b)
print('Confusion matrix:', gau_CM)
print ('Accuracy using GaussianNb:', accuracy_score(y,labels_b))
Confusion matrix: [[155  25]
 [ 59 261]]
Accuracy using GaussianNb: 0.832
PART D
Tuning your Models
TASK 1
Fine-tune the alpha parameter of the Bernoulli NB model and the var_smoothing parameter of the Gaussian NB model.

#First lets fine tune the Bernoulli NB classifier 


from sklearn.model_selection import StratifiedKFold, GridSearchCV

cv_method = StratifiedKFold(n_splits=5, random_state=999)


params_BER = [{'alpha':np.linspace(1,100,20)}]
bnb_classifier = BernoulliNB()
gs_BER = GridSearchCV(estimator=bnb_classifier, 
                     param_grid=params_BER, 
                     cv=cv_method,
                     verbose=1, 
                     scoring='accuracy')

gs_BER.fit(Data, target)
Fitting 5 folds for each of 20 candidates, totalling 100 fits
[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.3s finished
GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=999, shuffle=False),
             error_score=nan,
             estimator=BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None,
                                   fit_prior=True),
             iid='deprecated', n_jobs=None,
             param_grid=[{'alpha': array([  1.        ,   6.21052632,  11.42105263,  16.63157895,
        21.84210526,  27.05263158,  32.26315789,  37.47368421,
        42.68421053,  47.89473684,  53.10526316,  58.31578947,
        63.52631579,  68.73684211,  73.94736842,  79.15789474,
        84.36842105,  89.57894737,  94.78947368, 100.        ])}],
             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,
             scoring='accuracy', verbose=1)
gs_BER.best_score_
0.834
gs_BER.best_params_
{'alpha': 84.36842105263158}
TASK 2
#Now lets fine tune the GaussianNB classifier 


from sklearn.model_selection import StratifiedKFold, GridSearchCV

cv_method = StratifiedKFold(n_splits=5, random_state=999)


params_GAU = [{'var_smoothing':np.logspace(1,-9, num=200)}]
gau_classifier =  GaussianNB()
gs_GAU = GridSearchCV(estimator=gau_classifier, 
                     param_grid=params_GAU, 
                     cv=cv_method,
                     verbose=1, 
                     scoring='accuracy')

gs_GAU.fit(Data, target)
[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
Fitting 5 folds for each of 200 candidates, totalling 1000 fits
[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    2.8s finished
GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=999, shuffle=False),
             error_score=nan,
             estimator=GaussianNB(priors=None, var_smoothing=1e-09),
             iid='deprecated', n_jobs=None,
             param_grid=[{'var_smoothing': array([1.00000000e+01, 8.90735464e+00, 7.93409667e+00, 7.06718127e+00,
       6.29498899e+00, 5.60716994e+00, 4.99450512e+00, 4.44878283e+00,
       3.96268864e+00, 3.529...
       9.01101825e-09, 8.02643352e-09, 7.14942899e-09, 6.36824994e-09,
       5.67242607e-09, 5.05263107e-09, 4.50055768e-09, 4.00880633e-09,
       3.57078596e-09, 3.18062569e-09, 2.83309610e-09, 2.52353917e-09,
       2.24780583e-09, 2.00220037e-09, 1.78343088e-09, 1.58856513e-09,
       1.41499130e-09, 1.26038293e-09, 1.12266777e-09, 1.00000000e-09])}],
             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,
             scoring='accuracy', verbose=1)
gs_GAU.best_score_
0.8320000000000001
gs_GAU.best_params_
{'var_smoothing': 2.221946860939523}
# custom function to format the search results as a Pandas data frame
def get_search_results(gs):

    def model_result(scores, params):
        scores = {'mean_score': np.mean(scores),
             'std_score': np.std(scores),
             'min_score': np.min(scores),
             'max_score': np.max(scores)}
        return pd.Series({**params,**scores})

    models = []
    scores = []

    for i in range(gs.n_splits_):
        key = f"split{i}_test_score"
        r = gs.cv_results_[key]        
        scores.append(r.reshape(-1,1))

    all_scores = np.hstack(scores)
    for p, s in zip(gs.cv_results_['params'], all_scores):
        models.append((model_result(s, p)))

    pipe_results = pd.concat(models, axis=1).T.sort_values(['mean_score'], ascending=False)

    columns_first = ['mean_score', 'std_score', 'max_score', 'min_score']
    columns = columns_first + [c for c in pipe_results.columns if c not in columns_first]

    return pipe_results[columns]
results_Bernaulli = get_search_results(gs_BER)
results_Bernaulli.head()
mean_score	std_score	max_score	min_score	alpha
18	0.834	0.019	0.850	0.800	94.789
16	0.834	0.021	0.860	0.800	84.368
19	0.832	0.017	0.850	0.800	100.000
17	0.832	0.018	0.850	0.800	89.579
15	0.832	0.021	0.860	0.800	79.158
import altair as alt



results_BN = results_Bernaulli

alt.Chart(results_BN, 
          title='Bernauli Performance Comparison '
         ).mark_line(point=True).encode(
    alt.X('alpha', title='Value of Alpha'),
    alt.Y('mean_score', title='Accuracy Score', scale=alt.Scale(zero=False)),

)
#Get search results for Gaussian 

results_Gaussian = get_search_results(gs_GAU)
results_Gaussian.head()
mean_score	std_score	max_score	min_score	var_smoothing
13	0.832	0.016	0.860	0.810	2.222
20	0.832	0.029	0.880	0.790	0.988
19	0.832	0.029	0.880	0.790	1.110
12	0.830	0.018	0.860	0.810	2.495
37	0.830	0.026	0.870	0.790	0.138
import altair as alt

results_BN = results_Gaussian

alt.Chart(results_BN, 
          title='Gaussian Performance Comparison '
         ).mark_line(point=True).encode(
    alt.X('var_smoothing', title='Var Smoothing'),
    alt.Y('mean_score', title='Accuracy Score', scale=alt.Scale(zero=False)),

)
Part E
Hybrid NB
The purpose of this part is to implement a Hybrid NB Classifier on the "A3_Q1_train.csv" dataset that uses Bernoulli NB (with default parameters) 
for categorical descriptive features and Gaussian NB (with default parameters) for the numerical descriptive features. You will specifically train your Hybrid NB model using the train data and compute its accuracy on again train data.

Bernoulli NB that assumes all descriptive features are binary, and
Gaussian NB that assumes all descriptive features are numerical and they follow a Gaussian probability distribution.
from sklearn.ensemble import VotingClassifier
import warnings

#We use the categorical columns from the one hot encoded dataframe and fit a Bernaulli classifier to those values
hybrid_NB_B= df_all_cat_ohe.iloc[:,6:15]
hybrid_NB_Bclf = BernoulliNB()
bn_score= hybrid_NB_Bclf.fit(hybrid_NB_B,target).score(hybrid_NB_B,target)

#We use the numerical columns from the original dataframe after dropping the row_id column and fit a Gaussian 
#classifier to those values
hybrid_NB_G= df1.iloc[:,0:2]
hybrid_NB_Gclf= GaussianNB()
gnb_score =hybrid_NB_Gclf.fit(hybrid_NB_G,target).score(hybrid_NB_G,target)

hybrid_data = df1.iloc[:,0:2].join(df_all_cat_ohe.iloc[:,6:15])

hybridestimate = VotingClassifier(estimators=[('BNB',hybrid_NB_Bclf),('GNB',hybrid_NB_Gclf)], voting='soft',weights=[1,1])

hybridscore= hybridestimate.fit(hybrid_data,target).score(hybrid_data,target)

hybridscore
0.824
PART F
WRAPPING UP
#Summarizing the results as a Pandas df called df_summary

results = {'Method': ['Part B (Bernoulli NB)','Part C (Gaussian NB)','Part D (Tuned Bernoulli NB)','Part D (Tuned Gaussian NB)',
                     'Part E (Hybrid NB)'],
          'Accuracy':[0.832,0.832,0.834,0.832,0.824]}

df_summary =pd.DataFrame(data=results)
df_summary.round(3)
Method	Accuracy
0	Part B (Bernoulli NB)	0.832
1	Part C (Gaussian NB)	0.832
2	Part D (Tuned Bernoulli NB)	0.834
3	Part D (Tuned Gaussian NB)	0.832
4	Part E (Hybrid NB)	0.824
The hyper-parameter tuning improves the performance of the BernoulliNB. With default parameter alpha=1 we get 0.832 but with the hypertuned paramter {'alpha': 84.36842105263158} we get 0.834

On the other hand, hyper-parameter tuning does not improve the performance of the GaussianNB classifier . With default params {var_smoothingfloat, 1e-9} the scoring accuracy was 0.832 but with hypertuned params {'var_smoothing': 2.221946860939523} we get the same scoring accuracy of 0.832

So yes , we can say that hyper-paramter tuning did improve the performance of BernoulliNB but not GausssianNB

Finally a comment on the Hybrid NB model that is a combination of both Bernoulli and Gaussian. Intuitively one would have expected the Hybrid model to have performed better than both BernoulliNB and GausssianNB but it does not with a score of 0.824 which is less than both BernoulliNB 0.832 and GaussianNB 0.832
